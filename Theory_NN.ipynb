{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99cc66e",
   "metadata": {},
   "source": [
    "# Neural Networks definitions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd4dff",
   "metadata": {},
   "source": [
    "An artificial neural network is a type of artificial intelligence inspired by the learning mechanisms of the human brain. Its operation consists of a pool of simple processing units which communicate by sending signals to each other over a large number of weighted connections [1].\n",
    "\n",
    "The fundamental processing unit is known as an artificial neuron (or cell), which has the functionality of receiving input from neighbors or external sources, processing it, and propagating it to other units. The connection between the units is defined by the weight $w_{jk}$, which determines the effect that neuron $j$ has on neuron $k$. Regarding the input, there is a propagation rule which determines the effective input $s_k$ of a unit from its external input $\\theta_k$, known as bias. In this sense, an activation function $\\mathcal{F}_k$ determines the new level of activation based on $s_k$ and the current activation $y_k$, which is associated with the output of the unit.\n",
    "\n",
    "Generally, each unit is assumed to provide an additive contribution to the cell with which it is connected. The total input to neuron $k$ is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "    s_k  = \\sum_j w_{jk} y_j + \\theta_k,\n",
    "\\end{equation}\n",
    "\n",
    "where $y_j$ is the input from the neighboring units and $\\theta_k$ is the fixed bias term.\n",
    "\n",
    "The function $\\mathcal{F}_k$ receives the total input $s_k$ and the current activation $y_k$ to produce a new activation value $y_k(t+1)$. Often, $\\mathcal{F}_k$ can be represented as the sigmoid function, also known as logistic function, and it is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{F}(s_k) = \\frac{1}{1+ e^{-s_k}}.\n",
    "\\end{equation}\n",
    "\n",
    "Other functions, such as the sign function or the semi-linear function, can be implemented as the activation function. The sigmoid function is in the interval [0,1] and introduces an important feature regarding the non-linearity, which is essential for neural networks to learn complex relationships between inputs and outputs. Moreover, this function can be seen as the probability of getting some specifically output.\n",
    "\n",
    "Within neural networks, there are three main types of units: input units, output units, and hidden units. The input units receive data from external sources, whereas the output units transmit the final result out of the network. Between these layers, the hidden units receive input from previous units and apply both a weighted sum and a bias. Finally, these units apply a transfer function, such as the sigmoid, to the total input, thereby generating an internal activation signal."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
